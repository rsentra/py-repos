{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62feb49-42cc-4319-a118-db79fd3db660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09b034-df95-419b-95e0-3c3b47b93fc0",
   "metadata": {},
   "source": [
    "아래사이트를 참조하여 임베딩모델을 바꿈\n",
    "https://github.com/teddylee777/langchain-kr/blob/main/07-RAG/07-RAG-1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd721625-f211-4f3b-bfe4-20052a7cb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 디버깅을 위한 프로젝트명을 기입합니다.\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG TUTORIAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8a5a41-bced-41a1-8997-c4b05545f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa679df5-84f3-425f-9d46-b8cf92a0dc9f",
   "metadata": {},
   "source": [
    "웹 페이지의 내용을 로드하고, 텍스트를 청크로 나누어 인덱싱하는 과정을 거친 후, 관련된 텍스트 스니펫을 검색하여 새로운 내용을 생성하는 과정을 구현합니다.\n",
    "\n",
    "WebBaseLoader는 지정된 웹 페이지에서 필요한 부분만을 파싱하기 위해 bs4.SoupStrainer를 사용합니다.\n",
    "\n",
    "[참고]\n",
    "\n",
    "bs4.SoupStrainer 는 편리하게 웹에서 원하는 요소를 가져올 수 있도록 해줍니다.\n",
    "(예시)\n",
    "\n",
    "bs4.SoupStrainer(\n",
    "    \"div\",\n",
    "    attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]}, # 클래스 명을 입력\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f476f9-37f6-40bd-8e5b-ede30c880370",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1.문서로드 '''\n",
    "# 뉴스기사 내용을 로드하고, 청크로 나누고, 인덱싱합니다.\n",
    "url = \"https://n.news.naver.com/article/437/0000378416\"\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(url,),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb24e116-2892-4420-8100-d4b551064202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''2. 문서분할'''\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "471b9e70-ec74-4ea4-86b4-61bd272f902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3. 임베딩 & 벡터스토어 생성 '''\n",
    "# 벡터스토어를 생성합니다.\n",
    "# vectorstore = FAISS.from_documents(\n",
    "#     documents=splits, embedding=OpenAIEmbeddings())\n",
    "embeddings = HuggingFaceEmbeddings (\n",
    "    model_name = \"jhgan/ko-sroberta-multitask\",\n",
    "    model_kwargs = {'device':'cpu'},\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "   )\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents = splits, embedding = embeddings\n",
    ")\n",
    "# 뉴스에 포함되어 있는 정보를 검색하고 생성합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e1857-b9a0-45ed-a49f-b02bff306b2c",
   "metadata": {},
   "source": [
    "--------------------\n",
    "case: llm Chain 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6be4554b-d60a-4cb1-945c-48de705eb721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 1\n",
      "[HUMAN]\n",
      "부영그룹의 출산 장려 정책에 대해 설명해주세요\n",
      "\n",
      "[AI]\n",
      "부영그룹은 출산 장려 정책으로 2021년 이후 태어난 직원 자녀에 1억원씩, 총 70억원을 지원하고 앞으로도 지속할 계획이며, 연년생과 쌍둥이 자녀가 있는 경우 2억원을 받을 수 있습니다. 또한, 셋째를 낳는 경우 국민주택을 제공할 예정이며, 출산장려금을 받는 직원들의 세금 부담을 고려해 정부에 면세 제안을 할 예정입니다. 해당 정책은 사회적 분위기에서 확산되고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "''' 단계 4: 검색(Search) '''\n",
    "# 뉴스에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "''' 단계 5: 프롬프트 생성(Create Prompt) '''\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt\n",
    "\n",
    "\n",
    "''' 단계 6: 언어모델 생성(Create LLM) '''\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 검색한 문서 결과를 하나의 문단으로 합쳐줍니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "''' 단계 7: 체인 생성(Create Chain) '''\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "''' 단계 8: 체인 실행(Run Chain) '''\n",
    "def qa_rag(question):\n",
    "    response = rag_chain.invoke(question)\n",
    "    print(f\"[HUMAN]\\n{question}\\n\")\n",
    "    print(f\"[AI]\\n{response}\")\n",
    "    \n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"부영그룹의 출산 장려 정책에 대해 설명해주세요\"\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "qa_rag(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7935b97-ad41-4682-8682-cf43c7e92c21",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "case: ConversationalRetrievalChain 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f315b07-4ac8-4fbc-92c5-1bf262587e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm =  ChatOpenAI(openai_api_key=OPENAI_API_KEY,model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm =  ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "retriever = vectorstore.as_retriever(search_type='mmr', verbose=True)\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm = llm,\n",
    "    chain_type = 'stuff',\n",
    "    retriever = retriever,\n",
    "    memory = ConversationBufferMemory(memory_key='chat_history',return_messages=True, output_key='answer'),\n",
    "    return_source_documents = True,\n",
    "    verbose=True\n",
    "    )\n",
    "\n",
    "def qa_chat(query):\n",
    "    res = rag_chain({\"question\":query})\n",
    "    print(\"chat-history = \", res['chat_history'])\n",
    "    return res['answer']\n",
    "    \n",
    "query = \"부영그룹의 출산 장려 정책에 대해 설명해주세요\"\n",
    "print(qa_chat(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbfc15-7b71-4827-a65a-e3e4c20dad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"부영그룹은 출산 직원에게 얼마의 지원을 제공하나요?\"\n",
    "print(qa_chat(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765247a0-e08a-4c34-b4bf-7b336ec8f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이 함수는 vectorstore 객체의 delete_collection 메서드를 호출하여 컬렉션을 삭제합니다.\n",
    "#이는 데이터 정리 과정에서 사용되며, 특정 데이터셋이나 정보를 저장하는 컬렉션을 제거함으로써 \n",
    "#시스템의 저장 공간을 확보하고, 불필요한 데이터로 인한 혼란을 방지합니다.\n",
    "\n",
    "# 컬렉션을 삭제합니다.\n",
    "vectorstore.delete_collection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
